{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LY0SJUCSY305"
   },
   "source": [
    "#### Copyright 2018 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8Q1hsKyBZDVu"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5tftaRtUcm7"
   },
   "source": [
    "#Intro to Modeling\n",
    "\n",
    "\n",
    "**Learning Objectives:**\n",
    "* Become familiar with pandas for handling small datasets\n",
    "* Use the tf.Estimator and Feature Column API to experiment with feature transformations\n",
    "* Use visualizations and run experiments to understand the value of feature transformations\n",
    "\n",
    "Please **make a copy** of this Colab notebook before starting this lab. To do so, choose **File**->**Save a copy in Drive**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT_bZ9E0ZWaN"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "id": "wZ_T2SgDVKUH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/agussuyono/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sx4-PWE-VaD_"
   },
   "source": [
    "## Pandas, a helpful data analysis library for in-memory dataset\n",
    "\n",
    "We use a package called [Pandas](http://pandas.pydata.org/) for reading in our data, exploring our data and doing some basic processing. It is really helpful for datasets that fit in memory! And it has some nice integrations, as you will see.\n",
    "\n",
    "First we set up some options to control how items are displayed and the maximum number of rows to show when displaying a table.  Feel free to change this setup to whatever you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hKUIMcPCVRqv"
   },
   "outputs": [],
   "source": [
    "# Set pandas output display to have one digit for decimal places and limit it to\n",
    "# printing 15 rows.\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.options.display.max_rows = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_fTMztUVelY"
   },
   "source": [
    "### Load the dataset with pandas\n",
    "The car data set we will be using in this lab is provided as a comma separated file without a header row.  In order for each column to have a meaningful header name we must provide it.  We get the information about the columns from the [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile).\n",
    "\n",
    "We will use the features of the car, to try to predict its price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "code",
    "id": "Y38V73EgVYwt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set loaded. Num examples:  205\n"
     ]
    }
   ],
   "source": [
    "# Provide the names for the columns since the CSV file with the data does\n",
    "# not have a header row.\n",
    "feature_names = ['symboling', 'normalized-losses', 'make', 'fuel-type',\n",
    "        'aspiration', 'num-doors', 'body-style', 'drive-wheels',\n",
    "        'engine-location', 'wheel-base', 'length', 'width', 'height', 'weight',\n",
    "        'engine-type', 'num-cylinders', 'engine-size', 'fuel-system', 'bore',\n",
    "        'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg',\n",
    "        'highway-mpg', 'price']\n",
    "\n",
    "\n",
    "# Load in the data from a CSV file that is comma separated.\n",
    "car_data = pd.read_csv('https://storage.googleapis.com/mledu-datasets/cars_data.csv',\n",
    "                        sep=',', names=feature_names, header=None, encoding='latin-1')\n",
    "\n",
    "\n",
    "# We'll then randomize the data, just to be sure not to get any pathological\n",
    "# ordering effects that might harm the performance of Stochastic Gradient\n",
    "# Descent.\n",
    "car_data = car_data.reindex(np.random.permutation(car_data.index))\n",
    "\n",
    "print(\"Data set loaded. Num examples: \", len(car_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAHZBtDlkmGa"
   },
   "source": [
    "This is a really small dataset! Only 205 examples.\n",
    "\n",
    "For simplicity in this codelab, we do not split the data further into training and validation. But you MUST do this on real datasets, or else you will overfit to your single dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ1HxLrOVqZk"
   },
   "source": [
    "## Task 0: Use pandas to explore and prepare the data\n",
    "\n",
    "- Use Pandas to inspect the data and manually curate a list of numeric_feature_names and categorical_feature_names.\n",
    "\n",
    "\n",
    "Useful functions:\n",
    "- `type()` called on any Python object describes the type of the object\n",
    "- `dataframe[4:7]` pulls out rows 4, 5, 6 in a Pandas dataframe\n",
    "- `dataframe[['mycol1', 'mycol2']]` pulls out the two requested columns into a new Pandas dataframe\n",
    "- `dataframe['mycol1']` returns a Pandas series -- not a dataframe!\n",
    "- `dataframe.describe()` prints out statistics for each dataframe column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TfeHYeMf7PwQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>...</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>volvo</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>109.10</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.80</td>\n",
       "      <td>134</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>21485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>bmw</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>101.20</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.19</td>\n",
       "      <td>9.00</td>\n",
       "      <td>121</td>\n",
       "      <td>4250</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>20970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>dodge</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>93.70</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.23</td>\n",
       "      <td>9.40</td>\n",
       "      <td>68</td>\n",
       "      <td>5500</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>7609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symboling normalized-losses   make fuel-type aspiration num-doors  \\\n",
       "202         -1                95  volvo       gas        std      four   \n",
       "12           0               188    bmw       gas        std       two   \n",
       "26           1               148  dodge       gas        std      four   \n",
       "\n",
       "    body-style drive-wheels engine-location  wheel-base  ...  engine-size  \\\n",
       "202      sedan          rwd           front      109.10  ...          173   \n",
       "12       sedan          rwd           front      101.20  ...          164   \n",
       "26       sedan          fwd           front       93.70  ...           90   \n",
       "\n",
       "     fuel-system  bore  stroke compression-ratio horsepower  peak-rpm  \\\n",
       "202         mpfi  3.58    2.87              8.80        134      5500   \n",
       "12          mpfi  3.31    3.19              9.00        121      4250   \n",
       "26          2bbl  2.97    3.23              9.40         68      5500   \n",
       "\n",
       "    city-mpg highway-mpg  price  \n",
       "202       18          23  21485  \n",
       "12        21          28  20970  \n",
       "26        31          38   7609  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data[4:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>...</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>205.00</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205.00</td>\n",
       "      <td>...</td>\n",
       "      <td>205.00</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205.00</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205.00</td>\n",
       "      <td>205.00</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>nan</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>nan</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>nan</td>\n",
       "      <td>?</td>\n",
       "      <td>toyota</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.40</td>\n",
       "      <td>nan</td>\n",
       "      <td>68</td>\n",
       "      <td>5500</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>nan</td>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>185</td>\n",
       "      <td>168</td>\n",
       "      <td>114</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>202</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>94</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>nan</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.76</td>\n",
       "      <td>...</td>\n",
       "      <td>126.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.22</td>\n",
       "      <td>30.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.02</td>\n",
       "      <td>...</td>\n",
       "      <td>41.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.54</td>\n",
       "      <td>6.89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.60</td>\n",
       "      <td>...</td>\n",
       "      <td>61.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.50</td>\n",
       "      <td>...</td>\n",
       "      <td>97.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.00</td>\n",
       "      <td>...</td>\n",
       "      <td>120.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.40</td>\n",
       "      <td>...</td>\n",
       "      <td>141.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.90</td>\n",
       "      <td>...</td>\n",
       "      <td>326.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        symboling normalized-losses    make fuel-type aspiration num-doors  \\\n",
       "count      205.00               205     205       205        205       205   \n",
       "unique        nan                52      22         2          2         3   \n",
       "top           nan                 ?  toyota       gas        std      four   \n",
       "freq          nan                41      32       185        168       114   \n",
       "mean         0.83               NaN     NaN       NaN        NaN       NaN   \n",
       "std          1.25               NaN     NaN       NaN        NaN       NaN   \n",
       "min         -2.00               NaN     NaN       NaN        NaN       NaN   \n",
       "25%          0.00               NaN     NaN       NaN        NaN       NaN   \n",
       "50%          1.00               NaN     NaN       NaN        NaN       NaN   \n",
       "75%          2.00               NaN     NaN       NaN        NaN       NaN   \n",
       "max          3.00               NaN     NaN       NaN        NaN       NaN   \n",
       "\n",
       "       body-style drive-wheels engine-location  wheel-base  ...  engine-size  \\\n",
       "count         205          205             205      205.00  ...       205.00   \n",
       "unique          5            3               2         nan  ...          nan   \n",
       "top         sedan          fwd           front         nan  ...          nan   \n",
       "freq           96          120             202         nan  ...          nan   \n",
       "mean          NaN          NaN             NaN       98.76  ...       126.91   \n",
       "std           NaN          NaN             NaN        6.02  ...        41.64   \n",
       "min           NaN          NaN             NaN       86.60  ...        61.00   \n",
       "25%           NaN          NaN             NaN       94.50  ...        97.00   \n",
       "50%           NaN          NaN             NaN       97.00  ...       120.00   \n",
       "75%           NaN          NaN             NaN      102.40  ...       141.00   \n",
       "max           NaN          NaN             NaN      120.90  ...       326.00   \n",
       "\n",
       "        fuel-system  bore  stroke compression-ratio horsepower  peak-rpm  \\\n",
       "count           205   205     205            205.00        205       205   \n",
       "unique            8    39      37               nan         60        24   \n",
       "top            mpfi  3.62    3.40               nan         68      5500   \n",
       "freq             94    23      20               nan         19        37   \n",
       "mean            NaN   NaN     NaN             10.14        NaN       NaN   \n",
       "std             NaN   NaN     NaN              3.97        NaN       NaN   \n",
       "min             NaN   NaN     NaN              7.00        NaN       NaN   \n",
       "25%             NaN   NaN     NaN              8.60        NaN       NaN   \n",
       "50%             NaN   NaN     NaN              9.00        NaN       NaN   \n",
       "75%             NaN   NaN     NaN              9.40        NaN       NaN   \n",
       "max             NaN   NaN     NaN             23.00        NaN       NaN   \n",
       "\n",
       "       city-mpg highway-mpg price  \n",
       "count    205.00      205.00   205  \n",
       "unique      nan         nan   187  \n",
       "top         nan         nan     ?  \n",
       "freq        nan         nan     4  \n",
       "mean      25.22       30.75   NaN  \n",
       "std        6.54        6.89   NaN  \n",
       "min       13.00       16.00   NaN  \n",
       "25%       19.00       25.00   NaN  \n",
       "50%       24.00       30.00   NaN  \n",
       "75%       30.00       34.00   NaN  \n",
       "max       49.00       54.00   NaN  \n",
       "\n",
       "[11 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration',\n",
       "       'num-doors', 'body-style', 'drive-wheels', 'engine-location',\n",
       "       'wheel-base', 'length', 'width', 'height', 'weight', 'engine-type',\n",
       "       'num-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke',\n",
       "       'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg',\n",
       "       'highway-mpg', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183       volkswagen\n",
       "37             honda\n",
       "107           peugot\n",
       "123         plymouth\n",
       "202            volvo\n",
       "           ...      \n",
       "162           toyota\n",
       "168           toyota\n",
       "125          porsche\n",
       "88        mitsubishi\n",
       "69     mercedes-benz\n",
       "Name: make, Length: 205, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data['make']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['two', 'four', '?'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data['num-doors'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "id": "VsOUrVozoe9u"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c9c3a4c3a5a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# The correct solution will pass these assert statements.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_feature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_feature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LABEL = 'price'\n",
    "\n",
    "numeric_feature_names = car_data[['symboling','normalized-losses','wheel-base','engine-size','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg','price']]\n",
    "categorical_feature_names = list(set(feature_names) - set(numeric_feature_names) - set([LABEL]))\n",
    "\n",
    "# The correct solution will pass these assert statements.\n",
    "assert len(numeric_feature_names) == 15\n",
    "assert len(categorical_feature_names) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "lLFkHgBm8O1Y"
   },
   "outputs": [],
   "source": [
    "#@title Solution (to view code, from cell's menu, select Form -> Show Code)\n",
    "numeric_feature_names = ['symboling', 'normalized-losses', 'wheel-base',\n",
    "        'length', 'width', 'height', 'weight', 'engine-size', 'horsepower',\n",
    "        'peak-rpm', 'city-mpg', 'highway-mpg', 'bore', 'stroke',\n",
    "         'compression-ratio']\n",
    "\n",
    "categorical_feature_names = list(set(feature_names) - set(numeric_feature_names) - set([LABEL]))\n",
    "\n",
    "assert len(numeric_feature_names) == 15\n",
    "assert len(categorical_feature_names) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nabeQFGBpDEN"
   },
   "outputs": [],
   "source": [
    "# Run to inspect numeric features.\n",
    "car_data[numeric_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1ss9Q7mpiBy"
   },
   "outputs": [],
   "source": [
    "# Run to inspect categorical features.\n",
    "car_data[categorical_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OjDegBgqNnu"
   },
   "outputs": [],
   "source": [
    "# Coerce the numeric features to numbers. This is necessary because the model\n",
    "# crashes because not all the values are numeric.\n",
    "for feature_name in numeric_feature_names + [LABEL]:\n",
    "  car_data[feature_name] = pd.to_numeric(car_data[feature_name], errors='coerce')\n",
    "\n",
    "# Fill missing values with 0.\n",
    "# Is this an OK thing to do? You may want to come back and revisit this decision later.\n",
    "car_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uq-t-8GPvnCW"
   },
   "source": [
    "## Task 1: Make your best model with numeric features. No normalization allowed.\n",
    "\n",
    "Modify the model provided below to achieve the lowest eval loss. You may want to change various hyperparameters:\n",
    "- learning rate\n",
    "- choice of optimizer\n",
    "- hidden layer dimensions -- make sure your choice here makes sense given the number of training examples\n",
    "- batch size\n",
    "- num training steps\n",
    "- (anything else you can think of changing)\n",
    "\n",
    "Do not use the `normalizer_fn` arg on `numeric_column`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JH6KJp-4-E_Q"
   },
   "outputs": [],
   "source": [
    "# This code \"works\", but because of bad hyperparameter choices it gets NaN loss\n",
    "# during training. Try fixing this.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "print(numeric_feature_names)\n",
    "x_df = car_data[numeric_feature_names]\n",
    "y_series = car_data['price']\n",
    "\n",
    "# Create input_fn's so that the estimator knows how to read in your data.\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    y=y_series,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    y=y_series,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature columns allow the model to parse the data, perform common\n",
    "# preprocessing, and automatically generate an input layer for the tf.Estimator.\n",
    "model_feature_columns = [\n",
    "    tf.feature_column.numeric_column(feature_name) for feature_name in numeric_feature_names\n",
    "]\n",
    "print('model_feature_columns', model_feature_columns)\n",
    "\n",
    "est = tf.estimator.DNNRegressor(\n",
    "    feature_columns=model_feature_columns,\n",
    "    hidden_units=[64],\n",
    "    optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01),\n",
    "  )\n",
    "\n",
    "# TRAIN\n",
    "num_print_statements = 10\n",
    "num_training_steps = 10000\n",
    "for _ in range(num_print_statements):\n",
    "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
    "  scores = est.evaluate(eval_input_fn)\n",
    "  \n",
    "  # The `scores` dictionary has several metrics automatically generated by the\n",
    "  # canned Estimator.\n",
    "  # `average_loss` is the average loss for an individual example.\n",
    "  # `loss` is the summed loss for the batch.\n",
    "  # In addition to these scalar losses, you may find the visualization functions\n",
    "  # in the next cell helpful for debugging model quality.\n",
    "  print('scores', scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "3ptcfj_9Xi9M"
   },
   "outputs": [],
   "source": [
    "#@title Possible solution\n",
    "# Here is one possible solution:\n",
    "# The only necessary change to fix the NaN training loss was the choice of optimizer.\n",
    "\n",
    "# Changing other parameters could improve model quality, but take it with a\n",
    "# grain of salt. The dataset is very small.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "print(numeric_feature_names)\n",
    "x_df = car_data[numeric_feature_names]\n",
    "y_series = car_data['price']\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    y=y_series,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    y=y_series,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "# Feature columns allow the model to parse the data, perform common\n",
    "# preprocessing, and automatically generate an input layer for the tf.Estimator.\n",
    "model_feature_columns = [\n",
    "    tf.feature_column.numeric_column(feature_name) for feature_name in numeric_feature_names\n",
    "]\n",
    "print('model_feature_columns', model_feature_columns)\n",
    "\n",
    "est = tf.estimator.DNNRegressor(\n",
    "    feature_columns=model_feature_columns,\n",
    "    hidden_units=[64],\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.01),\n",
    "  )\n",
    "\n",
    "# TRAIN\n",
    "num_print_statements = 10\n",
    "num_training_steps = 10000\n",
    "for _ in range(num_print_statements):\n",
    "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
    "  scores = est.evaluate(eval_input_fn)\n",
    "  \n",
    "  # The `scores` dictionary has several metrics automatically generated by the \n",
    "  # canned Estimator.\n",
    "  # `average_loss` is the average loss for an individual example.\n",
    "  # `loss` is the summed loss for the batch.\n",
    "  # In addition to these scalar losses, you may find the visualization functions\n",
    "  # in the next cell helpful for debugging model quality.\n",
    "  print('scores', scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rxto3DwsjYw4"
   },
   "source": [
    "### Visualize your model's predictions\n",
    "\n",
    "After you have a trained model, it may be helpful to understand how your model's inference differs from the actual data.\n",
    "\n",
    "This helper function `scatter_plot_inference` does that for you. Real data is in grey. Your model's predictions are in orange.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGSXwX2fju1N"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def scatter_plot_inference_grid(est, x_df, feature_names):\n",
    "  \"\"\"Plots the predictions of the model against each feature.\n",
    "  \n",
    "  Args:\n",
    "    est: The trained tf.Estimator.\n",
    "    x_df: The pandas dataframe with the input data (used to create\n",
    "      predict_input_fn).\n",
    "    feature_names: An iterable of string feature names to plot.\n",
    "  \"\"\"\n",
    "  def scatter_plot_inference(axis,\n",
    "                             x_axis_feature_name,\n",
    "                             y_axis_feature_name,\n",
    "                             predictions):\n",
    "    \"\"\"Generate one subplot.\"\"\"\n",
    "    # Plot the real data in grey.\n",
    "    y_axis_feature_name = 'price'\n",
    "    axis.set_ylabel(y_axis_feature_name)\n",
    "    axis.set_xlabel(x_axis_feature_name)\n",
    "    axis.scatter(car_data[x_axis_feature_name],\n",
    "                 car_data[y_axis_feature_name],\n",
    "                 c='grey')\n",
    "\n",
    "    # Plot the predicted data in orange.\n",
    "    axis.scatter(car_data[x_axis_feature_name], predictions, c='orange')\n",
    "\n",
    "  predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "  predictions = [\n",
    "    x['predictions'][0]\n",
    "    for x in est.predict(predict_input_fn)\n",
    "  ]\n",
    "  \n",
    "  num_cols = 3\n",
    "  num_rows = int(math.ceil(len(feature_names)/float(num_cols)))\n",
    "  f, axarr = plt.subplots(num_rows, num_cols)\n",
    "  size = 4.5\n",
    "  f.set_size_inches(num_cols*size, num_rows*size)\n",
    "  \n",
    "  for i, feature_name in enumerate(numeric_feature_names):\n",
    "    axis = axarr[int(i/num_cols), i%num_cols]\n",
    "    scatter_plot_inference(axis, feature_name, 'price', predictions)\n",
    "  plt.show()\n",
    "\n",
    "scatter_plot_inference_grid(est, x_df, numeric_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBZI8f_8Yfph"
   },
   "source": [
    "## Task 2: Take your best numeric model from earlier. Add normalization.\n",
    "\n",
    "### Add normalization to your best numeric model from earlier\n",
    "\n",
    "- You decide what type of normalization to add, and for which features\n",
    "- You will need to use the `normalizer_fn` arg on [`numeric_column`](https://g3doc.corp.google.com/learning/brain/public/g3doc/api_docs/python/tf/feature_column/numeric_column.md?cl=head)\n",
    "    - An example of a silly normalizer_fn that shifts inputs down by 1, and then negates the value:\n",
    "    \n",
    "         normalizer_fn = lambda x: tf.neg(tf.subtract(x, 1))\n",
    "\n",
    "- You may find these pandas functions helpful:\n",
    "    - dataframe.mean()['your_feature_name']\n",
    "    - dataframe.std()['your_feature_name']\n",
    "- You will need to retune the hyperparameters from earlier.\n",
    "\n",
    "\n",
    "**Does normalization improve model quality on this dataset? Why or why not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jY_C_QgcZg1-"
   },
   "outputs": [],
   "source": [
    "# This 1D visualization of each numeric feature might inform your normalization\n",
    "# decisions.\n",
    "for feature_name in numeric_feature_names:\n",
    "  car_data.hist(column=feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiEpDZKSj8pN"
   },
   "source": [
    "###Train your model with numeric features + normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c30Y6IiR8iVn"
   },
   "outputs": [],
   "source": [
    "## Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxYJy71zaZsy"
   },
   "outputs": [],
   "source": [
    "#@title Possible solution\n",
    "# This does Z-score normalization since the distributions for most features looked\n",
    "# roughly normally distributed.\n",
    "\n",
    "# Z-score normalization subtracts the mean and divides by the standard deviation,\n",
    "# to give a roughly standard normal distribution (mean = 0, std = 1) under a\n",
    "# normal distribution assumption. Epsilon prevents divide by zero.\n",
    "\n",
    "# With normalization, are you able to get the model working with\n",
    "# GradientDescentOptimizer? Z-score normalization doesn't seem to be able to get\n",
    "# SGD working. Maybe a different type of normalization would?\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "print(numeric_feature_names)\n",
    "x_df = car_data[numeric_feature_names]\n",
    "y_series = car_data['price']\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    y=y_series,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    y=y_series,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "# Epsilon prevents divide by zero.\n",
    "epsilon = 0.000001\n",
    "model_feature_columns = [\n",
    "    tf.feature_column.numeric_column(feature_name,\n",
    "                                     normalizer_fn=lambda val: (val - x_df.mean()[feature_name]) / (epsilon + x_df.std()[feature_name]))\n",
    "    for feature_name in numeric_feature_names\n",
    "]\n",
    "print('model_feature_columns', model_feature_columns)\n",
    "\n",
    "est = tf.estimator.DNNRegressor(\n",
    "    feature_columns=model_feature_columns,\n",
    "    hidden_units=[64],\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.01),\n",
    "  )\n",
    "\n",
    "# TRAIN\n",
    "num_print_statements = 10\n",
    "num_training_steps = 10000\n",
    "for _ in range(num_print_statements):\n",
    "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
    "  scores = est.evaluate(eval_input_fn)\n",
    "  \n",
    "  # The `scores` dictionary has several metrics automatically generated by the \n",
    "  # canned Estimator.\n",
    "  # `average_loss` is the average loss for an individual example.\n",
    "  # `loss` is the summed loss for the batch.\n",
    "  # In addition to these scalar losses, you may find the visualization functions\n",
    "  # in the next cell helpful for debugging model quality.\n",
    "  print('scores', scores)\n",
    "\n",
    "scatter_plot_inference_grid(est, x_df, numeric_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fruh0Qj5_Bos"
   },
   "source": [
    "## Task 3: Make your best model using only categorical features\n",
    "\n",
    "- Look at the possible feature columns for categorical features. They begin with `categorical_column_with_` in go/tf-ops.\n",
    "- You may find `dataframe[categorical_feature_names].unique()` helpful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "-udhHnNS2WvN"
   },
   "outputs": [],
   "source": [
    "## Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EftIzPAI9RJj"
   },
   "outputs": [],
   "source": [
    "#@title Possible solution\n",
    "# We have the full list of values that each feature takes on, and the list is\n",
    "# relatively small so we use categorical_column_with_vocabulary_list.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "x_df = car_data[categorical_feature_names]\n",
    "y_series = car_data['price']\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    y=y_series,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    y=y_series,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "model_feature_columns = [\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            feature_name, vocabulary_list=car_data[feature_name].unique()))\n",
    "    for feature_name in categorical_feature_names\n",
    "]\n",
    "print('model_feature_columns', model_feature_columns)\n",
    "\n",
    "est = tf.estimator.DNNRegressor(\n",
    "    feature_columns=model_feature_columns,\n",
    "    hidden_units=[64],\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.01),\n",
    "  )\n",
    "\n",
    "# TRAIN\n",
    "num_print_statements = 10\n",
    "num_training_steps = 10000\n",
    "for _ in range(num_print_statements):\n",
    "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
    "  scores = est.evaluate(eval_input_fn)\n",
    "  \n",
    "  # The `scores` dictionary has several metrics automatically generated by the\n",
    "  # canned Estimator.\n",
    "  # `average_loss` is the average loss for an individual example.\n",
    "  # `loss` is the summed loss for the batch.\n",
    "  # In addition to these scalar losses, you may find the visualization functions\n",
    "  # in the next cell helpful for debugging model quality.\n",
    "  print('scores', scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyBH5Wai_HTD"
   },
   "source": [
    "## Task 4: Using all the features, make the best model that you can make\n",
    "\n",
    "With all the features combined, your model should perform better than your earlier models using numerical and categorical models alone. Tune your model until that is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNfCzC-q8edv"
   },
   "outputs": [],
   "source": [
    "## Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmaGHWFVGKMr"
   },
   "outputs": [],
   "source": [
    "#@title Possible solution\n",
    "# This is a first pass at a model that uses all the features.\n",
    "# Do you have any improvements?\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "x_df = car_data[numeric_feature_names + categorical_feature_names]\n",
    "y_series = car_data['price']\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    y=y_series,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    y=y_series,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=x_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "epsilon = 0.000001\n",
    "model_feature_columns = [\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            feature_name, vocabulary_list=car_data[feature_name].unique()))\n",
    "    for feature_name in categorical_feature_names\n",
    "] + [\n",
    "    tf.feature_column.numeric_column(feature_name,\n",
    "                                     normalizer_fn=lambda val: (val - x_df.mean()[feature_name]) / (epsilon + x_df.std()[feature_name]))\n",
    "    for feature_name in numeric_feature_names\n",
    "]\n",
    "\n",
    "\n",
    "print('model_feature_columns', model_feature_columns)\n",
    "\n",
    "est = tf.estimator.DNNRegressor(\n",
    "    feature_columns=model_feature_columns,\n",
    "    hidden_units=[64],\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.01),\n",
    "  )\n",
    "\n",
    "# TRAIN\n",
    "num_print_statements = 10\n",
    "num_training_steps = 10000\n",
    "for _ in range(num_print_statements):\n",
    "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
    "  scores = est.evaluate(eval_input_fn)\n",
    "  \n",
    "  # The `scores` dictionary has several metrics automatically generated by the \n",
    "  # canned Estimator.\n",
    "  # `average_loss` is the average loss for an individual example.\n",
    "  # `loss` is the summed loss for the batch.\n",
    "  # In addition to these scalar losses, you may find the visualization functions\n",
    "  # in the next cell helpful for debugging model quality.\n",
    "  print('scores', scores)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Intro-to-modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
